{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"machine_learning_benchmark.ipynb","provenance":[],"collapsed_sections":["biI_BGE4mnk2"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_KYxnqzKCy4h"},"source":["# 1) Main"]},{"cell_type":"markdown","metadata":{"id":"L7RwAdoCFaRE"},"source":["## 1.1) Connect Google Drive with Google Colaboratory"]},{"cell_type":"code","metadata":{"id":"PnGc-3s1C1dn"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJu9nrcMWhOn"},"source":["## 1.2) Install Nilearn"]},{"cell_type":"code","metadata":{"id":"LOrrihzuC9Bz"},"source":["!pip install nilearn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VOSKhipjWap1"},"source":["## 1.3) Import libraries"]},{"cell_type":"code","metadata":{"id":"L-8ExFkpCy4r"},"source":["import os\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import errno\n","\n","import nilearn as nl\n","from nilearn import datasets\n","from nilearn.input_data import NiftiLabelsMasker\n","from nilearn.connectome import ConnectivityMeasure\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import confusion_matrix\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier as KNN\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qWKMPfmNXWi4"},"source":["## 1.4) Define the path where this notebook is located <-- **EDIT !**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZBhvy-OragAn"},"source":["For example, if this notebook is inside a folder with the name `benchmark`, in your google drive, the path is defined as:\n","\n","> `path_main = '/content/drive/MyDrive/benchmark'`\n","\n","As shown in the example, you should NOT add a slash (/) at the end of the indicated path."]},{"cell_type":"code","metadata":{"id":"Ti3upqYQC40n"},"source":["###################### EDIT ! #########################\n","path_main = '/content/drive/MyDrive/myFolder'\n","#######################################################\n","\n","# Check if the path is correct\n","notebook_name = 'machine_learning_benchmark.ipynb'\n","if os.path.isfile(path_main+'/'+ notebook_name):\n","  print('Correct path') \n","else:\n","  print('Error: incorrect path')\n","  print('- Check if this notebook is within the indicated path')\n","  print('- Check the name of this notebook is: '+notebook_name)    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ma-Q9rG5l-G3"},"source":["# 2) Functions"]},{"cell_type":"markdown","metadata":{"id":"OS3zjYaBk_Dq"},"source":["In this notebook, the Preprocessed Connectomes Project (PCP) nomenclature is used to define the four strategies, which differs from that of our paper. Therefore, the following lines show the equivalent between the PCP nomenclature (left) and that of our paper (right).\n","\n","\n","> `filt_global = BPF+GSR`\n","\n","> `filt_noglobal = BPF`\n","\n","> `nofilt_global = GSR`\n","\n","> `nofilt_noglobal = none`"]},{"cell_type":"markdown","metadata":{"id":"5_t8x_O1mHnR"},"source":["## 2.1) Define strategy using a Boolean vector"]},{"cell_type":"markdown","metadata":{"id":"negXs1rV9Mq8"},"source":["This function returns a Boolean vector to identify the desired strategy when downloading the data."]},{"cell_type":"code","metadata":{"id":"M9ShBiyclhA8"},"source":["def bool_strategy(name_strategy):\n","  if name_strategy == 'filt_global':\n","    bool_vector = np.array([True, True], dtype=bool)\n","  if name_strategy == 'filt_noglobal':\n","    bool_vector = np.array([True, False], dtype=bool)\n","  if name_strategy == 'nofilt_global':\n","    bool_vector = np.array([False, True], dtype=bool)\n","  if name_strategy == 'nofilt_noglobal':\n","    bool_vector = np.array([False, False], dtype=bool) \n","    \n","  return bool_vector"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uErdkpND1zJE"},"source":["## 2.2) Extract features"]},{"cell_type":"markdown","metadata":{"id":"JNqBuAnSEkBf"},"source":["This function allows extracting the features of the cases and storing them in a file with extension `.npz`. Specifically, for each case, a one-dimensional vector of features with length `L = 2016` is obtained."]},{"cell_type":"code","metadata":{"id":"UdkgkhouXgR8"},"source":["def features_all(path_output, strategy, path_cases):\n","  name_save = strategy+'_features_all.npz'\n","  \n","  # Load atlas\n","  multiscale = datasets.fetch_atlas_basc_multiscale_2015()\n","  atlas_filename = multiscale.scale064\n","  \n","  # Initialize masker object\n","  masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True, verbose=0)\n","  \n","  # Initialize correlation measure\n","  correlation_measure = ConnectivityMeasure(kind='correlation', vectorize=True, discard_diagonal=True)\n","\n","  print('\\n----> Strategy: '+strategy)\n","\n","  try: # Check if the feature file exists\n","    # Load features\n","    feat_file = os.path.join(path_output, name_save)\n","    features = np.load(feat_file)['a']\n","    print(\"Feature file found\")\n","\n","  except: # If not, extract features\n","    features = []\n","    print(\"No feature file found. Extracting features ...\")\n","\n","    for i,case in enumerate(path_cases):\n","        # Extract the time series from the ROI's\n","        time_series = masker.fit_transform(case)      \n","        \n","        # Create correlation matrix\n","        correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n","        \n","        features.append(correlation_matrix)\n","        print('Features %s of %s extracted'%(i+1,len(path_cases)))\n","\n","    # Save features\n","    np.savez_compressed(os.path.join(path_output, name_save), a = features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iuRGIDI5poj"},"source":["## 2.3) Get target"]},{"cell_type":"markdown","metadata":{"id":"AGrC97bPHH-l"},"source":["This function returns two vectors (`train_target` and `validation_target`) containing the labels (`1` for autism or `2` for normal patient) of the cases used in the `train` and `validation` sets defined in each fold."]},{"cell_type":"code","metadata":{"id":"E_R3M6w_jh04"},"source":["def get_target(path_main, fold):\n","  with open(path_main+'/folds.pickle', 'rb') as op1:\n","    folds = pickle.load(op1)\n","  path_dxgroup = pd.read_csv(path_main+'/path_dxgroup.csv')\n","  train_target = np.array([(path_dxgroup['dx_group'])[i] for i,case in enumerate(path_dxgroup['file_id']) if case not in folds['fold'+str(fold)]])\n","  validation_target = np.array([(path_dxgroup['dx_group'])[i] for i,case in enumerate(path_dxgroup['file_id']) if case in folds['fold'+str(fold)]])\n","  \n","  return train_target, validation_target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pYLV7IPhCy4z"},"source":["## 2.4) Grid search method"]},{"cell_type":"markdown","metadata":{"id":"pyJ_EJvdTQV-"},"source":["This function uses the grid search method to find the best model for each machine learning algorithm. In this way, it returns two variables corresponding to the best model and the best parameters found, respectively."]},{"cell_type":"code","metadata":{"id":"B5hWTdetCy42"},"source":["def best_estimator(model, param_grid, features, target, cv):\n","  grid = GridSearchCV(model, param_grid, cv=cv)\n","  grid.fit(features, target)\n","  best_model = grid.best_estimator_\n","  best_param = grid.best_params_\n","  \n","  return best_model, best_param"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"biI_BGE4mnk2"},"source":["# 3) Download preprocessed rs-fMRI data\n"]},{"cell_type":"markdown","metadata":{"id":"yWG2dENnPeCi"},"source":["At this point the rs-fMRI data are downloaded according to the preprocessing strategy. Specifically, data from the NYU site through the CPAC pipeline are considered."]},{"cell_type":"code","metadata":{"id":"h2iVKOYVmmq0"},"source":["path_donwload = path_main\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","for strategy in strategies:\n","  bool_vector = bool_strategy(strategy)\n","  abide_asd = datasets.fetch_abide_pcp(data_dir = path_donwload, pipeline = \"cpac\", band_pass_filtering = bool_vector[0],                               \n","                                   global_signal_regression = bool_vector[1], quality_checked = False, SITE_ID=['NYU'], DX_GROUP=['1'])\n","  \n","  abide_tc = datasets.fetch_abide_pcp(data_dir = path_donwload, pipeline = \"cpac\", band_pass_filtering = bool_vector[0],                               \n","                                   global_signal_regression = bool_vector[1], quality_checked = False, SITE_ID=['NYU'], DX_GROUP=['2'])\n","   \n","  abide_asd = abide_tc = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60IJVC_1kEvl"},"source":["# 4) Paths, id and dx_group of the cases"]},{"cell_type":"markdown","metadata":{"id":"S-4oCkoP85Ez"},"source":["This section allows to create a file with `.csv` extension containing the `paths` of the cases, depending on the strategy, the `id` (e.g., NYU_0050952) and the `dx_group` (1 is a patient with autism and 2 is a normal patient)."]},{"cell_type":"code","metadata":{"id":"as1tq9dVP8En"},"source":["strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","extra_pheno = ['file_id', 'dx_group']\n","pheno = pd.read_csv(path_main+'/ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv')\n","fileid_dxgroup = [[pheno.FILE_ID[i], pheno.DX_GROUP[i]] for i in range(len(pheno)) if (pheno.FILE_ID[i])[0:4] == 'NYU_']\n","path_dxgroup = pd.DataFrame(columns=strategies+extra_pheno)\n","for strategy in strategies:\n","  path_dxgroup[strategy] = [path_main+'/ABIDE_pcp/cpac/'+strategy+'/'+str(i[0])+'_func_preproc.nii.gz' for i in fileid_dxgroup]\n","path_dxgroup['file_id'] = [str(i[0]) for i in fileid_dxgroup]\n","path_dxgroup['dx_group'] = [str(i[1]) for i in fileid_dxgroup]\n","path_dxgroup.to_csv(path_main+'/path_dxgroup.csv') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQwaYHjBCy4t"},"source":["# 5) Feature extraction"]},{"cell_type":"markdown","metadata":{"id":"a4BVS8Mb17f_"},"source":["## 5.1) Features of all cases according to the strategy"]},{"cell_type":"markdown","metadata":{"id":"2AGlJdQtvjLF"},"source":["In this section we obtain the characteristics of all cases for each preprocessing strategy."]},{"cell_type":"code","metadata":{"id":"PhCmuGaCeI6r"},"source":["path_output = path_main+'/features'\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","try:\n","  os.mkdir(path_output)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","path_cases = pd.read_csv(path_main+'/path_dxgroup.csv')\n","for strategy in strategies:\n","  features_all(path_output, strategy, path_cases[strategy])  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pnd0MPSqDud2"},"source":["## 5.2) Features according to strategy and fold"]},{"cell_type":"markdown","metadata":{"id":"SKPInAgRwhF9"},"source":["In this section the files are created, by strategy, containing the characteristics of the cases belonging to the train or validation sets defined in each fold."]},{"cell_type":"code","metadata":{"id":"oyvup9GucEdy"},"source":["path_output = path_main+'/features'\n","num_folds = 5\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","with open(path_main+'/folds.pickle', 'rb') as op1:\n","    folds = pickle.load(op1)\n","\n","path_dxgroup = pd.read_csv(path_main+'/path_dxgroup.csv')\n","\n","for strategy in strategies:\n","  print('----> Strategy: '+strategy)\n","  features_each_fold = {}\n","  features = np.load(path_output+'/'+strategy+'_features_all.npz')['a']\n","  for fold in range(1, num_folds+1):\n","    features_train = np.array([features[i,:] for i,case in enumerate(path_dxgroup['file_id']) if case not in folds['fold'+str(fold)]])\n","    features_validation = np.array([features[i,:] for i,case in enumerate(path_dxgroup['file_id']) if case in folds['fold'+str(fold)]])\n","    features_each_fold['fold'+str(fold)+'_train'] = features_train\n","    features_each_fold['fold'+str(fold)+'_validation'] = features_validation\n","  np.savez_compressed(os.path.join(path_output, strategy+'_features_folds'), **features_each_fold)\n","  features = features_each_fold = []    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"99J3-s0P6u05"},"source":["# 6) Machine learning algorithms"]},{"cell_type":"markdown","metadata":{"id":"OnA03HnvCy43"},"source":["## 6.1) Support Vector Machines (SVM)"]},{"cell_type":"code","metadata":{"id":"32EUE1StCy4z"},"source":["path_output = path_main+'/features'\n","path_models = path_main+'/models'\n","num_folds = 5\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","try:\n","  os.mkdir(path_models)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","measures_svm_strtg = []\n","\n","for strategy in strategies:\n","  print('\\n----> Strategy: '+strategy)\n","  measures_svm_folds = []\n","\n","  for fold in range(1, num_folds+1):\n","    print('Fold: '+str(fold))\n","    file_features = np.load(os.path.join(path_output, strategy+'_features_folds.npz'))\n","    train_features = file_features['fold'+str(fold)+'_train']\n","    validation_features = file_features['fold'+str(fold)+'_validation']\n","    train_target, validation_target = get_target(path_main, fold)\n","    model_svm = SVC()\n","\n","    try: # Check if the file containing the best model exists\n","      # Load best model\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_svm.pickle', 'rb') as om:\n","        best_model_svm = pickle.load(om)\n","      \n","    except: # If not, search for the best model\n","      param_grid_svm = {'C': [0.01, 0.1, 1, 1.2, 1.3, 1.4, 1.5, 2, 3, 4,  5, 10],\n","                        'gamma': [0.00001, 0.00005,  0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2, 3.5, 5, 10]}\n","\n","      _, best_params_svm = best_estimator(model_svm, param_grid_svm, train_features, train_target, 10)\n","\n","      best_model_svm = SVC(C=best_params_svm['C'], break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","                          decision_function_shape='ovr', degree=3, gamma=best_params_svm['gamma'], kernel='rbf',\n","                          max_iter=-1, probability=False, random_state=None, shrinking=True,\n","                          tol=0.001, verbose=False)\n","\n","      # Save best_model_svm\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_svm.pickle', 'wb') as ff1:\n","          pickle.dump(best_model_svm, ff1)\n","\n","    clf_svm = best_model_svm.fit(train_features, train_target)\n","    pred_target = clf_svm.predict(validation_features)\n","\n","    pred_target[pred_target==2] = 0\n","    validation_target[validation_target==2] = 0\n","    \n","    TN, FP, FN, TP = (confusion_matrix(validation_target, pred_target).ravel()).astype(float)\n","\n","    accuracy = (TP+TN)/(TP+TN+FP+FN)\n","    specificity = TN/(FP+TN)\n","    precision = TP/(TP+FP)\n","    recall = TP/(TP+FN)\n","    fscore = 2*TP/((2*TP)+FP+FN)\n","\n","    measures_svm = [accuracy, precision, fscore, recall, specificity]\n","\n","    measures_svm_folds.append(measures_svm)\n","\n","    # Delete content of some variables\n","    model_SVC = train_features = validation_features = train_target = validation_target = []\n","    om = ff1 = best_model_svm = best_params_svm = clf_svm = pred_target = measures_svm = []\n","\n","  measures_svm_strtg.append(np.array(measures_svm_folds).mean(axis=0)) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XpbVE3us0KR6"},"source":["### Save results - SVM"]},{"cell_type":"code","metadata":{"id":"tGAL08r0hkal"},"source":["path_results = path_main+'/results'\n","\n","try:\n","  os.mkdir(path_results)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","# Save measures\n","with open(path_results+'/measures_svm.pickle', 'wb') as ff1:\n","    pickle.dump(measures_svm_strtg, ff1)\n","\n","ff1 = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG33l67y1C60"},"source":["### Table of results - SVM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"iDKn8QOztuaO","executionInfo":{"status":"ok","timestamp":1627838148946,"user_tz":300,"elapsed":285,"user":{"displayName":"William Cancino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihgRNgXPyBrzkK9YAa5PKAotO962x2MLPQ-aTyUPU=s64","userId":"02525392572347657825"}},"outputId":"03d92e61-23ef-4334-d362-824260d76628"},"source":["measures_names = ['Accuracy', 'Precision', 'F-score', 'Recall', 'Specificity']\n","table_svm = pd.DataFrame(columns=measures_names, index=strategies)\n","measures_svm_strtg = (np.array(measures_svm_strtg)*1000).astype(int)/1000\n","pd.options.display.float_format = '{:,.3f}'.format\n","\n","for i, strategy in enumerate(strategies):\n","  table_svm.loc[strategy] = measures_svm_strtg[i]\n","\n","table_svm"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>F-score</th>\n","      <th>Recall</th>\n","      <th>Specificity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>filt_global</th>\n","      <td>0.680</td>\n","      <td>0.685</td>\n","      <td>0.556</td>\n","      <td>0.480</td>\n","      <td>0.830</td>\n","    </tr>\n","    <tr>\n","      <th>filt_noglobal</th>\n","      <td>0.685</td>\n","      <td>0.701</td>\n","      <td>0.536</td>\n","      <td>0.440</td>\n","      <td>0.870</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_global</th>\n","      <td>0.697</td>\n","      <td>0.698</td>\n","      <td>0.605</td>\n","      <td>0.546</td>\n","      <td>0.809</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_noglobal</th>\n","      <td>0.645</td>\n","      <td>0.668</td>\n","      <td>0.483</td>\n","      <td>0.386</td>\n","      <td>0.840</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Accuracy Precision F-score Recall Specificity\n","filt_global        0.680     0.685   0.556  0.480       0.830\n","filt_noglobal      0.685     0.701   0.536  0.440       0.870\n","nofilt_global      0.697     0.698   0.605  0.546       0.809\n","nofilt_noglobal    0.645     0.668   0.483  0.386       0.840"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Ajj2Tk8nCy49"},"source":["## 6.2) K-Neirest Neighbor (KNN)"]},{"cell_type":"code","metadata":{"id":"8rE31bqqK6Gl"},"source":["path_output = path_main+'/features'\n","path_models = path_main+'/models'\n","num_folds = 5\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","\n","try:\n","  os.mkdir(path_models)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","measures_knn_strtg = [] \n","\n","for strategy in strategies:\n","  print('\\n----> Strategy: '+strategy)\n","  measures_knn_folds = []\n","\n","  for fold in range(1, num_folds+1):\n","    print('Fold: '+str(fold))\n","    file_features = np.load(os.path.join(path_output, strategy+'_features_folds.npz'))\n","    train_features = file_features['fold'+str(fold)+'_train']\n","    validation_features = file_features['fold'+str(fold)+'_validation']\n","    train_target, validation_target = get_target(path_main, fold)\n","    model_knn = KNN()\n","\n","    try: # Check if the file containing the best model exists\n","      # Load best model\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_knn.pickle', 'rb') as om:\n","        best_model_knn = pickle.load(om)    \n","\n","    except: # If not, search for the best model \n","      param_grid_knn = {'n_neighbors': [1, 2 , 3, 4, 6, 10, 15, 20, 25, 30, 50, 100],\n","                        'algorithm':['auto', 'kd_tree']}\n","\n","      _, best_params_knn = best_estimator(model_knn, param_grid_knn, train_features, train_target, 10)\n","\n","      best_model_knn = KNN(algorithm=best_params_knn['algorithm'], leaf_size=30, metric='minkowski',\n","                          metric_params=None, n_jobs=None, n_neighbors=best_params_knn['n_neighbors'], p=2,\n","                          weights='uniform')\n","\n","      # Save best_model_knn\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_knn.pickle', 'wb') as ff1:\n","          pickle.dump(best_model_knn, ff1)\n","\n","    clf_knn = best_model_knn.fit(train_features, train_target)\n","    pred_target = clf_knn.predict(validation_features)\n","\n","    pred_target[pred_target==2] = 0\n","    validation_target[validation_target==2] = 0\n","\n","    TN, FP, FN, TP = (confusion_matrix(validation_target, pred_target).ravel()).astype(float)\n","\n","    accuracy = (TP+TN)/(TP+TN+FP+FN)\n","    precision = TP/(TP+FP)\n","    fscore = 2*TP/((2*TP)+FP+FN)\n","    recall = TP/(TP+FN)\n","    specificity = TN/(FP+TN)\n","\n","    measures_knn = [accuracy, precision, fscore, recall, specificity]\n","\n","    measures_knn_folds.append(measures_knn)\n","\n","    # Delete content of some variables\n","    model_knn = train_features = validation_features = train_target = validation_target = []\n","    om = ff1 = best_model_knn = best_params_knn = clf_knn = pred_target = measures_knn = []\n","\n","  measures_knn_strtg.append(np.array(measures_knn_folds).mean(axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCtSKe0-zffM"},"source":["### Save results - KNN"]},{"cell_type":"code","metadata":{"id":"nqNYSpS2-DYB"},"source":["path_results = path_main+'/results'\n","\n","try:\n","  os.mkdir(path_results)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","# Save measures\n","with open(path_results+'/measures_knn.pickle', 'wb') as ff1:\n","    pickle.dump(measures_knn_strtg, ff1)\n","\n","ff1 = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RdoORxrpziSI"},"source":["### Table of results - KNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"ixAfFR5Fumat","executionInfo":{"status":"ok","timestamp":1627838379870,"user_tz":300,"elapsed":211,"user":{"displayName":"William Cancino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihgRNgXPyBrzkK9YAa5PKAotO962x2MLPQ-aTyUPU=s64","userId":"02525392572347657825"}},"outputId":"e3b06daf-bf32-470c-a20b-cd40d0495350"},"source":["measures_names = ['Accuracy', 'Precision', 'F-score', 'Recall', 'Specificity']\n","table_knn = pd.DataFrame(columns=measures_names, index=strategies)\n","measures_knn_strtg = (np.array(measures_knn_strtg)*1000).astype(int)/1000\n","pd.options.display.float_format = '{:,.3f}'.format\n","\n","for i, strategy in enumerate(strategies):\n","  table_knn.loc[strategy] = measures_knn_strtg[i]\n","\n","table_knn"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>F-score</th>\n","      <th>Recall</th>\n","      <th>Specificity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>filt_global</th>\n","      <td>0.639</td>\n","      <td>0.618</td>\n","      <td>0.509</td>\n","      <td>0.440</td>\n","      <td>0.790</td>\n","    </tr>\n","    <tr>\n","      <th>filt_noglobal</th>\n","      <td>0.600</td>\n","      <td>0.537</td>\n","      <td>0.437</td>\n","      <td>0.386</td>\n","      <td>0.760</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_global</th>\n","      <td>0.634</td>\n","      <td>0.600</td>\n","      <td>0.501</td>\n","      <td>0.439</td>\n","      <td>0.780</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_noglobal</th>\n","      <td>0.600</td>\n","      <td>0.556</td>\n","      <td>0.487</td>\n","      <td>0.453</td>\n","      <td>0.710</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Accuracy Precision F-score Recall Specificity\n","filt_global        0.639     0.618   0.509  0.440       0.790\n","filt_noglobal      0.600     0.537   0.437  0.386       0.760\n","nofilt_global      0.634     0.600   0.501  0.439       0.780\n","nofilt_noglobal    0.600     0.556   0.487  0.453       0.710"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"5ojh3uriCy5E"},"source":["## 6.3) Decision Tree (DT)"]},{"cell_type":"code","metadata":{"id":"PEtZ_jgIXp_A"},"source":["path_output = path_main+'/features'\n","path_models = path_main+'/models'\n","num_folds = 5\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","\n","try:\n","  os.mkdir(path_models)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","measures_dt_strtg = []\n","\n","for strategy in strategies:\n","  print('\\n----> Strategy: '+strategy)\n","  measures_dt_folds = []\n","\n","  for fold in range(1, num_folds+1):\n","    print('Fold: '+str(fold))\n","    file_features = np.load(os.path.join(path_output, strategy+'_features_folds.npz'))\n","    train_features = file_features['fold'+str(fold)+'_train']\n","    validation_features = file_features['fold'+str(fold)+'_validation']\n","    train_target, validation_target = get_target(path_main, fold)   \n","    model_dt = DecisionTreeClassifier(random_state=1)\n","\n","    try: # Check if the file containing the best model exists\n","      # Load best model\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_dt.pickle', 'rb') as om:\n","        best_model_dt = pickle.load(om)   \n","\n","    except: # If not, search for the best model\n","      param_grid_dt = {'max_depth': [1, 2 , 3, 4, 5, 6, 10]}\n","\n","      _ , best_params_dt = best_estimator(model_dt, param_grid_dt, train_features, train_target, 10)\n","\n","      best_model_dt = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                              max_depth=best_params_dt['max_depth'], max_features=None, max_leaf_nodes=None,\n","                              min_impurity_decrease=0.0, min_impurity_split=None,\n","                              min_samples_leaf=1, min_samples_split=2,\n","                              min_weight_fraction_leaf=0.0, presort='deprecated',\n","                              random_state=1, splitter='best')\n","\n","      # Save model_best tree\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_dt.pickle', 'wb') as ff1:\n","          pickle.dump(best_model_dt, ff1)\n","\n","    clf_dt = best_model_dt.fit(train_features, train_target)\n","    pred_target = clf_dt.predict(validation_features)\n","\n","    pred_target[pred_target==2] = 0\n","    validation_target[validation_target==2] = 0\n","\n","    TN, FP, FN, TP = (confusion_matrix(validation_target, pred_target).ravel()).astype(float)\n","\n","    accuracy = (TP+TN)/(TP+TN+FP+FN)\n","    precision = TP/(TP+FP)\n","    fscore = 2*TP/(2*TP+FP+FN)\n","    recall = TP/(TP+FN)\n","    specificity = TN/(FP+TN)\n","\n","    measures_dt = [accuracy, precision, fscore, recall, specificity]\n","\n","    measures_dt_folds.append(measures_dt)\n","\n","    # Delete content of some variables\n","    model_dt = train_features = validation_features = train_target = validation_target = []\n","    om = ff1 = best_model_dt = best_params_dt = clf_dt = pred_target = measures_dt = []\n","\n","  measures_dt_strtg.append(np.array(measures_dt_folds).mean(axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0wUva5Qyt39"},"source":["### Save results - DT"]},{"cell_type":"code","metadata":{"id":"mTqAW7PJCy5F"},"source":["path_results = path_main+'/results'\n","\n","try:\n","  os.mkdir(path_results)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","# Save measures\n","with open(path_results+'/measures_dt.pickle', 'wb') as ff1:\n","    pickle.dump(measures_dt_strtg, ff1)\n","\n","ff1 = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7r8OCwQvysGO"},"source":["### Table of results - DT"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"dpgcxw3GvUC5","executionInfo":{"status":"ok","timestamp":1627838565839,"user_tz":300,"elapsed":219,"user":{"displayName":"William Cancino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihgRNgXPyBrzkK9YAa5PKAotO962x2MLPQ-aTyUPU=s64","userId":"02525392572347657825"}},"outputId":"1bf02c46-6bc1-4fa4-cdf9-83c08a4c1b17"},"source":["measures_names = ['Accuracy', 'Precision', 'F-score', 'Recall', 'Specificity']\n","table_dt = pd.DataFrame(columns=measures_names, index=strategies)\n","measures_dt_strtg = (np.array(measures_dt_strtg)*1000).astype(int)/1000\n","pd.options.display.float_format = '{:,.3f}'.format\n","\n","for i, strategy in enumerate(strategies):\n","  table_dt.loc[strategy] = measures_dt_strtg[i]\n","\n","table_dt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>F-score</th>\n","      <th>Recall</th>\n","      <th>Specificity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>filt_global</th>\n","      <td>0.565</td>\n","      <td>0.527</td>\n","      <td>0.513</td>\n","      <td>0.533</td>\n","      <td>0.590</td>\n","    </tr>\n","    <tr>\n","      <th>filt_noglobal</th>\n","      <td>0.559</td>\n","      <td>0.485</td>\n","      <td>0.486</td>\n","      <td>0.493</td>\n","      <td>0.610</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_global</th>\n","      <td>0.628</td>\n","      <td>0.603</td>\n","      <td>0.500</td>\n","      <td>0.440</td>\n","      <td>0.770</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_noglobal</th>\n","      <td>0.571</td>\n","      <td>0.495</td>\n","      <td>0.476</td>\n","      <td>0.466</td>\n","      <td>0.650</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Accuracy Precision F-score Recall Specificity\n","filt_global        0.565     0.527   0.513  0.533       0.590\n","filt_noglobal      0.559     0.485   0.486  0.493       0.610\n","nofilt_global      0.628     0.603   0.500  0.440       0.770\n","nofilt_noglobal    0.571     0.495   0.476  0.466       0.650"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"IQYl0OGYCy5H"},"source":["## 6.4) Random Forests (RF)"]},{"cell_type":"code","metadata":{"id":"o977witMU5KL"},"source":["path_output = path_main+'/features'\n","path_models = path_main+'/models'\n","num_folds = 5\n","strategies = ['filt_global', 'filt_noglobal', 'nofilt_global', 'nofilt_noglobal']\n","\n","\n","try:\n","  os.mkdir(path_models)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","measures_rf_strtg = []\n","\n","for strategy in strategies:\n","  print('\\n----> Strategy: '+strategy)\n","  measures_rf_folds = [] \n","\n","  for fold in range(1, num_folds+1):\n","    print('Fold: '+str(fold))\n","    file_features = np.load(os.path.join(path_output, strategy+'_features_folds.npz'))\n","    train_features = file_features['fold'+str(fold)+'_train']\n","    validation_features = file_features['fold'+str(fold)+'_validation']\n","    train_target, validation_target = get_target(path_main, fold)\n","    model_rf = RandomForestClassifier(random_state=42)\n","\n","    try: # Check if the file containing the best model exists\n","      # Load best model\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_rf.pickle', 'rb') as om:\n","        best_model_rf = pickle.load(om)   \n","\n","    except: # If not, search for the best model    \n","      param_grid_rf = {'n_estimators': [100, 200, 500, 700],\n","                       'max_features': ['sqrt', 'log2']}    \n","\n","      best_model_rf, best_params_rf = best_estimator(model_rf, param_grid_rf, train_features, train_target, 10)\n","\n","      # Save best_model_rf\n","      with open(path_models+'/'+strategy+'_fold'+str(fold)+'_best_model_rf.pickle', 'wb') as ff1:\n","          pickle.dump(best_model_rf, ff1)\n","\n","    clf_rf = best_model_rf.fit(train_features, train_target)\n","    pred_target = clf_rf.predict(validation_features)\n","\n","    pred_target[pred_target==2] = 0\n","    validation_target[validation_target==2] = 0\n","\n","    TN, FP, FN, TP = (confusion_matrix(validation_target, pred_target).ravel()).astype(float)\n","\n","    accuracy = (TP+TN)/(TP+TN+FP+FN)\n","    precision = TP/(TP+FP)\n","    fscore = 2*TP/((2*TP)+FP+FN)\n","    recall = TP/(TP+FN)\n","    specificity = TN/(FP+TN)\n","\n","    measures_rf = [accuracy, precision, fscore, recall, specificity]\n","\n","    measures_rf_folds.append(measures_rf)\n","\n","    # Delete content of some variables\n","    model_rf = train_features = validation_features = train_target = validation_target = []\n","    om = ff1 = model_best_rf = best_params_rf = clf_rf = pred_target = measures_rf = []\n","\n","  measures_rf_strtg.append(np.array(measures_rf_folds).mean(axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0KbukEWGxJP2"},"source":["### Save results - RF"]},{"cell_type":"code","metadata":{"id":"e2wRIrVICy5H"},"source":["path_results = path_main+'/results'\n","\n","try:\n","  os.mkdir(path_results)\n","except OSError as exc:\n","  if exc.errno != errno.EEXIST:\n","    raise\n","  pass\n","\n","with open(path_results+'/measures_rf.pickle', 'wb') as ff1:\n","    pickle.dump(measures_rf_strtg, ff1)\n","\n","ff1 = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_qrh7ywYxG6F"},"source":["### Table of results - RF"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"fna35E_Ox_r6","executionInfo":{"status":"ok","timestamp":1627840371187,"user_tz":300,"elapsed":210,"user":{"displayName":"William Cancino","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihgRNgXPyBrzkK9YAa5PKAotO962x2MLPQ-aTyUPU=s64","userId":"02525392572347657825"}},"outputId":"0e953808-a1ca-4132-fb7b-1508dbc3e20e"},"source":["measures_names = ['Accuracy', 'Precision', 'F-score', 'Recall', 'Specificity']\n","table_rf = pd.DataFrame(columns=measures_names, index=strategies)\n","measures_rf_strtg = (np.array(measures_rf_strtg)*1000).astype(int)/1000\n","pd.options.display.float_format = '{:,.3f}'.format\n","\n","for i, strategy in enumerate(strategies):\n","  table_rf.loc[strategy] = measures_rf_strtg[i]\n","\n","table_rf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>F-score</th>\n","      <th>Recall</th>\n","      <th>Specificity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>filt_global</th>\n","      <td>0.617</td>\n","      <td>0.640</td>\n","      <td>0.410</td>\n","      <td>0.319</td>\n","      <td>0.840</td>\n","    </tr>\n","    <tr>\n","      <th>filt_noglobal</th>\n","      <td>0.674</td>\n","      <td>0.734</td>\n","      <td>0.505</td>\n","      <td>0.386</td>\n","      <td>0.889</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_global</th>\n","      <td>0.679</td>\n","      <td>0.740</td>\n","      <td>0.507</td>\n","      <td>0.386</td>\n","      <td>0.900</td>\n","    </tr>\n","    <tr>\n","      <th>nofilt_noglobal</th>\n","      <td>0.651</td>\n","      <td>0.725</td>\n","      <td>0.468</td>\n","      <td>0.360</td>\n","      <td>0.869</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Accuracy Precision F-score Recall Specificity\n","filt_global        0.617     0.640   0.410  0.319       0.840\n","filt_noglobal      0.674     0.734   0.505  0.386       0.889\n","nofilt_global      0.679     0.740   0.507  0.386       0.900\n","nofilt_noglobal    0.651     0.725   0.468  0.360       0.869"]},"metadata":{"tags":[]},"execution_count":18}]}]}